# Machine Learning Engineer Nanodegree
## Capstone Proposal
Matt Agee  
September 20, 2017

## Proposal

### Domain Background
The domain of this proposal will be fashion. The global fashion industry is valued at roughly $3 trillion dollars [1] with many news outlets like Vogue, Cosmopolitan, and Elle specialized to covering it. Fashion is inherently visual, so naturally these news outlets produce a large amount of image data. If this data can be aggregated and annotated, applications guiding a user's fashion decisions may be developed. 

This proposal will focus on the problem of annotating image data. Specifically, it will attempt to determine what classes of clothing are present in an image and where in the image they are. This problem has been examined before [2,3,4] and the datasets for these attempts have been made public. I will be using the DeepFashion dataset for my attempts. 

My personal motivation does not stem from fashion itself, but more from the large amount of professional quality photographs and oped pieces generated by the industry. If this unstructured data can be given some structure, I expect some high quality machine learning applications of general public interest could be produced. 

### Problem Statement

Given an image containing clothing items of some kind, determine which clothing items are present. Then perform image segmentation and identify which segments correspond to which clothing items. 

### Datasets and Inputs

The dataset used will be the Attribute Prediction subset of the DeepFashion dataset [5]. The dataset contains the following information:

- 289,222 clothing images
- 50 clothing categories with 1000 attributes
- bounding box annotations and clothing type

For this project I will only be making use of the images, 50 clothing categories and bounding box annotations. To reduce the problem complexity I will also only consider the 10 most frequent clothing categories. 

### Solution Statement

The problem will be considered solved when two criteria are met: 

- A classifier capable of identifying the clothing items in an image has been trained to greater than 90% accuracy. 
- A segmentation algorithm capable of accurately bounding and labeling clothing items has been created. 

### Benchmark Model

There will be benchmark models for both the classification task and the segmentation task. The benchmark for the classification task will be the unoptimized ImageNet models. ImageNet contains several clothing classes [6], these will be mapped to the closest considered analog in the DeepFashion dataset. 

The bounding boxes created as part of the segmentation task (described below) will be compared against the bounding boxes created by the pretrained fashion_detector.caffe [4] model bounding boxes. This model outputs bounding boxes for only three clothing classes: upper, lower, and full body. The categories I use may be mapped to these classes as described in the supplementary material linked in [5]. 

The metrics used for comparison are described in the next section. 

### Evaluation Metrics

Three metrics will be used to evaluate performance.
The first metric will simply be the identification accuracy for each clothing category as measured against the dataset labels. 

The segmentation must also be evaluated, but the dataset only has bounding boxes. So, to facilitate comparison, the segmentation will be transformed into a bounding box by using the most extreme pixels in the x and y to define a bounding box. The resultant bounding box will then be compared to the dataset's bounding box according to the Intersection over Union (IoU) [7] and center correctness measure [8]. 

### Project Design

The proposal encompasses three distinct problems. The approach to each of these problems are discussed below. This proposal is preliminary, implementation details may be revised as the model develops.  

#### Clothing Identification
A multiclass classifier will be trained to recognize the ten most frequent clothing categories. To assist in training, transfer learning will be employed. Multiple ImageNet trained neural nets like Inception, Resnet and GoogLeNet will be tried as the base. The layer at which to unfreeze the weights will also be experimented with. The classification accuracy averaged across classes will be used to as the scoring function. 

#### Image Segmentation
The image segmentation step will be based on the normalized cuts algorithm [9]. The similarity measure used to define the weights will be defined as in the paper, with the RGB images mapped to grayscale. However, I will also experiment with using linear combinations of the RGB channel values to weight the similarity. The algorithm will be performed recursively on each segment until a minimum cut value is reached, or the recursion depth grows too large. The similarity across each boundary may then be computed and used to define boundary strength. This boundary strength may be thresholded to create a hierarchy of segmentations.  

If this method of generating regions proves too time consuming I may use the SLIC [10] algorithm to generate superpixels. I will then use them in the normalized cuts algorithm or directly merge adjacent regions based on boundary strength to generate the hierarchy of segmentations. 

#### Segment Classification
The classification step will be partially combined with the segmentation step and will make use of the hierarchy of segmentations produced by the above methods. The algorithm proceeds in two steps:

	Step One:
	For each segment in the set of coarsest grain segments:
		1. Replace all other segments with a null pattern. 
		2. Run the resulting image through the previously trained classifier.
		3. If an object is detected, repeat step one for the set of coarsest grain segments belonging to this segment. 
	If no object detected for a given loop over segments, restore the segments looped over and proceed to step two.  

	Step Two:
	For each of the finest grain segments in the considered segment:
		1. Replace the segment with a null pattern.
		2. Classify the resulting image.
		3. If no object detected, mark the nulled segment as belonging to the object, restore it and proceed
		4. If object remains detectable, keep the segment nulled and proceed. 
	
To work, the segments in step two can't be so small that removing one belonging to the object keeps the object recognizable. Proceeding to step two too early will also cause performance issues. Some heuristic will need to be developed to make sure the segments in step two are large enough. 

I expect the choice of null pattern will affect the method's success. As such, the null pattern choice will be treated as another parameter for the segmentation method. Each combination of parameters will be evaluated based on the IoU and center correctness measures previously mentioned. 

I couldn't find this technique in the literature. It will be less efficient than simply classifying the most probable object proposals (like [11,12]) and taking the object proposal region to be the full region. The approach taken in Step two will also likely underspecify the object segmentation. I'm still curious to see how it works though. 

### References
1. FashionUnited 2017: https://fashionunited.com/global-fashion-industry-statistics
- paperdoll previous work: http://vision.is.tohoku.ac.jp/~kyamagu/papers/yamaguchi2014retrieving.pdf
- Outfit segmentation: http://image.ntua.gr/iva/files/kalantidis_icmr13.pdf
- Fashion detector: https://github.com/liuziwei7/fashion-detection
- Deep Fashion: http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html
- ImageNet classes: https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a
- Intersection over Union: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/
- Center Correctness: http://cs231n.stanford.edu/reports/2016/pdfs/285_Report.pdf
- Normalized Cuts: https://people.eecs.berkeley.edu/~malik/papers/SM-ncut.pdf
- SLIC - http://www.kev-smith.com/papers/SLIC_Superpixels.pdf
- multiscale combinatorial grouping for object proposal recognition: https://arxiv.org/pdf/1503.00848.pdf
- convolutional oriented bounds: https://github.com/kmaninis/COB